---
description: FastAPI endpoints in llm-food, including synchronous and asynchronous file processing
globs: llm_food/app.py
alwaysApply: false
---
# FastAPI Server Endpoints

The `llm-food` API is built using FastAPI and provides both synchronous and asynchronous endpoints for file conversion. The endpoints are designed to handle different types of document processing needs efficiently.

## Key Design Principles

1. **Synchronous vs Non-Blocking Operations:**
   - Synchronous operations for immediate file conversion (`/convert`)
   - Non-blocking batch processing for multiple files (`/batch`)
   - Thread pool execution for CPU-intensive operations

2. **File Handling:**
   - Immediate temporary file creation for uploaded files
   - Proper cleanup of temporary files
   - Efficient memory usage by avoiding in-memory file storage

3. **Authentication:**
   - Optional Bearer token authentication
   - Configurable via environment variables

## Endpoint Overview

### 1. Synchronous Conversion (`/convert`)
- Handles single file uploads
- Immediate processing and response
- Supports various file formats (PDF, DOCX, RTF, PPTX, HTML)

### 2. Batch Processing (`/batch`)
- Non-async endpoint running in FastAPI's thread pool
- Immediate temporary file creation
- Background task processing
- Progress tracking via status endpoint
- Efficient memory usage

### 3. Status and Results (`/status/{task_id}`, `/batch/{task_id}`)
- Track batch job progress
- Retrieve completed results
- Error reporting and handling

## Implementation Details

### Batch Processing Flow

```python
@app.post("/batch", dependencies=[Depends(authenticate_request)])
def batch_files_upload(
    background_tasks: BackgroundTasks,
    files: List[UploadFile],
    output_gcs_path: str,
):
    # Create temporary files immediately
    temp_files = []
    for f in files:
        temp_file = tempfile.NamedTemporaryFile(suffix=ext, delete=False)
        temp_files.append(temp_file.name)
        shutil.copyfileobj(f.file, temp_file)
        temp_file.close()

    # Process files in background tasks
    background_tasks.add_task(
        _process_single_non_pdf_file_and_upload,
        temp_file_path,  # Pass file path instead of content
        ...
    )

    return {"task_id": main_batch_job_id}
```

### Background Processing Functions

The background processing functions are designed to be non-async to run efficiently in FastAPI's thread pool:

```python
def _run_gemini_pdf_batch_conversion(
    pdf_inputs_list: List[tuple[str, str]],  # (filename, temp_file_path)
    output_gcs_path_str: str,
    main_batch_job_id: str,
    gemini_batch_sub_job_id: str,
):
    # Process PDFs using Gemini Batch API
    # Runs in thread pool, non-blocking
    ...

def _process_single_non_pdf_file_and_upload(
    temp_file_path: str,
    file_ext: str,
    original_filename: str,
    ...
):
    # Process non-PDF files
    # Runs in thread pool, non-blocking
    ...
```

### Status Management

```python
def _check_and_finalize_batch_job_status(
    main_batch_job_id: str,
    con: duckdb.DuckDBPyConnection,
):
    # Non-async status check and update
    # Called by background tasks
    ...
```

## Best Practices

1. **Memory Management:**
   - Use temporary files instead of in-memory storage
   - Clean up temporary files after processing
   - Stream file uploads to disk

2. **Error Handling:**
   - Proper cleanup in case of errors
   - Detailed error reporting in database
   - Status updates for failed operations

3. **Database Operations:**
   - Consistent transaction handling
   - Status updates for tracking
   - Proper connection management

4. **Background Tasks:**
   - Non-async processing functions for thread pool execution
   - Progress tracking and status updates
   - Resource cleanup

## Configuration

The server can be configured through environment variables:
- `LLM_FOOD_HOST`: Server host (default: "0.0.0.0")
- `LLM_FOOD_PORT`: Server port (default: 8000)
- `LLM_FOOD_RELOAD`: Enable/disable reload in development
- `API_AUTH_TOKEN`: Optional authentication token 